{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import collections\n",
    "import math\n",
    "import torch\n",
    "import os, tarfile, json\n",
    "import time, datetime\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import estimator, PyTorchModel, PyTorchPredictor, PyTorch\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.predictor import numpy_deserializer, npy_serializer\n",
    "import boto3\n",
    "from types import SimpleNamespace\n",
    "from PIL import Image\n",
    "import base64\n",
    "from matplotlib import patches\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = 'privisaa-bucket-virginia'#sagemaker_session.default_bucket() # can replace with your own S3 bucket 'privisaa-bucket-virginia' # \n",
    "prefix = 'detectron2'\n",
    "runtime_client = boto3.client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-26 23:17:36--  https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 152130221 (145M) [application/octet-stream]\n",
      "Saving to: ‘/home/ec2-user/SageMaker/model_final_5bd44e.pkl’\n",
      "\n",
      "/home/ec2-user/Sage 100%[===================>] 145.08M  24.6MB/s    in 6.4s    \n",
      "\n",
      "2020-08-26 23:17:43 (22.6 MB/s) - ‘/home/ec2-user/SageMaker/model_final_5bd44e.pkl’ saved [152130221/152130221]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/138363263/model_final_59f53c.pkl -O /home/ec2-user/SageMaker/model_final_59f53c.pkl\n",
    "# !wget https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl -O /home/ec2-user/SageMaker/model_final_5bd44e.pkl\n",
    "!wget https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl -O /home/ec2-user/SageMaker/code/object-tracking-project/detectron2_train/model_final_5bd44e.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to decide how to implement predictor.py \n",
    "Vadim's method uses the input_fn and model_fn approach, the BERT NGC version builds its own flask app, you should try Vadim's way first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  528.6MB\n",
      "Step 1/17 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.5.1-gpu-py36-cu101-ubuntu16.04\n",
      " ---> 99faf8ca49f3\n",
      "Step 2/17 : RUN pip install --upgrade --force-reinstall torch torchvision cython\n",
      " ---> Using cache\n",
      " ---> d15cd6cc6eab\n",
      "Step 3/17 : RUN pip install sagemaker==1.72.0 sagemaker_inference boto3 # needed for debug purposes only\n",
      " ---> Using cache\n",
      " ---> 1a8e89f02ead\n",
      "Step 4/17 : RUN pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
      " ---> Using cache\n",
      " ---> 0c8c0e035736\n",
      "Step 5/17 : RUN pip install 'git+https://github.com/facebookresearch/fvcore'\n",
      " ---> Using cache\n",
      " ---> a12ae96e11d7\n",
      "Step 6/17 : ENV FORCE_CUDA=\"1\"\n",
      " ---> Using cache\n",
      " ---> e3c7179c164b\n",
      "Step 7/17 : ENV TORCH_CUDA_ARCH_LIST=\"Volta\"\n",
      " ---> Using cache\n",
      " ---> aabc2cb5b143\n",
      "Step 8/17 : RUN pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
      " ---> Using cache\n",
      " ---> 61092a7c9083\n",
      "Step 9/17 : COPY detectron2 /opt/ml/detectron2\n",
      " ---> Using cache\n",
      " ---> 2b70e96792c9\n",
      "Step 10/17 : WORKDIR /opt/ml\n",
      " ---> Using cache\n",
      " ---> 896c595f8ca1\n",
      "Step 11/17 : COPY detectron2/configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml /opt/ml/mask_rcnn_R_50_FPN_inference_acc_test.yaml\n",
      " ---> Using cache\n",
      " ---> ac7ba1511c36\n",
      "Step 12/17 : COPY detectron2/configs/quick_schedules/retinanet_R_50_FPN_inference_acc_test.yaml /opt/ml/retinanet_R_50_FPN_inference_acc_test.yaml\n",
      " ---> Using cache\n",
      " ---> ba8987cdbb76\n",
      "Step 13/17 : COPY detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml /opt/ml/mask_rcnn_R_50_FPN_3x.yaml\n",
      " ---> Using cache\n",
      " ---> 3df5fb572981\n",
      "Step 14/17 : COPY detectron2/configs/COCO-Detection/retinanet_R_50_FPN_3x.yaml /opt/ml/retinanet_R_50_FPN_3x.yaml\n",
      " ---> Using cache\n",
      " ---> 620c320e9028\n",
      "Step 15/17 : COPY detectron2/configs/Base-RCNN-FPN.yaml /opt/ml/Base-RCNN-FPN.yaml\n",
      " ---> Using cache\n",
      " ---> c8d3c52bb2e1\n",
      "Step 16/17 : COPY detectron2/configs/Base-RetinaNet.yaml /opt/ml/Base-RetinaNet.yaml\n",
      " ---> Using cache\n",
      " ---> 6e4fd1195767\n",
      "Step 17/17 : ENV FVCORE_CACHE=\"/tmp\"\n",
      " ---> Using cache\n",
      " ---> 7df4d322ded1\n",
      "Successfully built 7df4d322ded1\n",
      "Successfully tagged detectron2-serve:latest\n",
      "The push refers to repository [209419068016.dkr.ecr.us-east-1.amazonaws.com/detectron2-serve]\n",
      "396790c1460f: Preparing\n",
      "b54c46b4d1ad: Preparing\n",
      "f3eb8c2541dc: Preparing\n",
      "4fc025a239d0: Preparing\n",
      "1b777299b5b0: Preparing\n",
      "55771bfff376: Preparing\n",
      "3c25e068a40f: Preparing\n",
      "e2d142af2dff: Preparing\n",
      "6453170b826e: Preparing\n",
      "7ee934d2d73f: Preparing\n",
      "fa13d8def4f2: Preparing\n",
      "e4eec9687c6a: Preparing\n",
      "5c474cf150f9: Preparing\n",
      "57cc070fdbf0: Preparing\n",
      "c7563f381989: Preparing\n",
      "356b2bfead12: Preparing\n",
      "3c25e068a40f: Waiting\n",
      "b22d778548ce: Preparing\n",
      "88f6bafb8fa7: Preparing\n",
      "e2d142af2dff: Waiting\n",
      "a846a934b0df: Preparing\n",
      "7d706619b6d2: Preparing\n",
      "f845cc356c8c: Preparing\n",
      "a160e71e883a: Preparing\n",
      "0004f3f1463b: Preparing\n",
      "3d75876ff095: Preparing\n",
      "200533908bdd: Preparing\n",
      "e1ca5b593e3b: Preparing\n",
      "6a671a38318c: Preparing\n",
      "fc73260fc70b: Preparing\n",
      "52ed25d00bb6: Preparing\n",
      "a1029ccfe508: Preparing\n",
      "f9f939aaf404: Preparing\n",
      "c25d9333c486: Preparing\n",
      "b7ee80f86be3: Preparing\n",
      "aa7f8c8d5f39: Preparing\n",
      "48817fbd6c92: Preparing\n",
      "1b039d138968: Preparing\n",
      "6453170b826e: Waiting\n",
      "7082d7d696f8: Preparing\n",
      "7ee934d2d73f: Waiting\n",
      "b22d778548ce: Waiting\n",
      "0004f3f1463b: Waiting\n",
      "fa13d8def4f2: Waiting\n",
      "55771bfff376: Waiting\n",
      "e4eec9687c6a: Waiting\n",
      "a846a934b0df: Waiting\n",
      "3d75876ff095: Waiting\n",
      "a160e71e883a: Waiting\n",
      "5c474cf150f9: Waiting\n",
      "f845cc356c8c: Waiting\n",
      "57cc070fdbf0: Waiting\n",
      "e1ca5b593e3b: Waiting\n",
      "7d706619b6d2: Waiting\n",
      "c7563f381989: Waiting\n",
      "6a671a38318c: Waiting\n",
      "48817fbd6c92: Waiting\n",
      "356b2bfead12: Waiting\n",
      "fc73260fc70b: Waiting\n",
      "c25d9333c486: Waiting\n",
      "f9f939aaf404: Waiting\n",
      "1b039d138968: Waiting\n",
      "a1029ccfe508: Waiting\n",
      "aa7f8c8d5f39: Waiting\n",
      "b7ee80f86be3: Waiting\n",
      "1b777299b5b0: Layer already exists\n",
      "b54c46b4d1ad: Layer already exists\n",
      "396790c1460f: Layer already exists\n",
      "f3eb8c2541dc: Layer already exists\n",
      "4fc025a239d0: Layer already exists\n",
      "55771bfff376: Layer already exists\n",
      "3c25e068a40f: Layer already exists\n",
      "e2d142af2dff: Layer already exists\n",
      "6453170b826e: Layer already exists\n",
      "7ee934d2d73f: Layer already exists\n",
      "fa13d8def4f2: Layer already exists\n",
      "e4eec9687c6a: Layer already exists\n",
      "5c474cf150f9: Layer already exists\n",
      "c7563f381989: Layer already exists\n",
      "57cc070fdbf0: Layer already exists\n",
      "356b2bfead12: Layer already exists\n",
      "b22d778548ce: Layer already exists\n",
      "88f6bafb8fa7: Layer already exists\n",
      "a846a934b0df: Layer already exists\n",
      "7d706619b6d2: Layer already exists\n",
      "0004f3f1463b: Layer already exists\n",
      "f845cc356c8c: Layer already exists\n",
      "3d75876ff095: Layer already exists\n",
      "a160e71e883a: Layer already exists\n",
      "200533908bdd: Layer already exists\n",
      "6a671a38318c: Layer already exists\n",
      "e1ca5b593e3b: Layer already exists\n",
      "fc73260fc70b: Layer already exists\n",
      "a1029ccfe508: Layer already exists\n",
      "52ed25d00bb6: Layer already exists\n",
      "f9f939aaf404: Layer already exists\n",
      "c25d9333c486: Layer already exists\n",
      "1b039d138968: Layer already exists\n",
      "b7ee80f86be3: Layer already exists\n",
      "48817fbd6c92: Layer already exists\n",
      "aa7f8c8d5f39: Layer already exists\n",
      "7082d7d696f8: Layer already exists\n",
      "latest: digest: sha256:8e4e9a1ea7271a8b901c0f9db08724d7538e2a84012cd2f97f04194ce168ea4d size: 8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=detectron2-serve\n",
    "\n",
    "chmod +x train\n",
    "chmod +x serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "# some kind of security auth issue with pushing this to ecr, not authorized to perform ecr:InitiateLayerUpload\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model as a tarball\n",
    "with tarfile.open('d2.tar.gz', 'w:gz') as f:\n",
    "    f.add('/home/ec2-user/SageMaker/model_final_5bd44e.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "#local deploy\n",
    "container_serving = \"detectron2-serve\" # your container name\n",
    "tag = \"latest\" # you can have several version of container available\n",
    "#image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, container_serving, tag)\n",
    "\n",
    "model = PyTorchModel(\n",
    "                     name = \"local-1\",\n",
    "                     model_data=model_data,\n",
    "                     role=role,\n",
    "                     entry_point=\"predict_coco.py\", source_dir=\"/home/ec2-user/SageMaker/detectron2_train\",\n",
    "                     framework_version=\"1.5.1\", py_version=\"3.6\",\n",
    "                     image='209419068016.dkr.ecr.us-east-1.amazonaws.com/detectron2-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpdv6ae4d7_algo-1-f6lb3_1\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m nginx: /opt/conda/lib/libtiff.so.5: no version information available (required by /usr/lib/x86_64-linux-gnu/libgd.so.3)\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 2020/07/15 18:33:24 [crit] 19#19: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:33:24 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 2020/07/15 18:33:29 [crit] 19#19: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:33:29 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 2020/07/15 18:33:34 [crit] 19#19: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:33:34 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m Building wheels for collected packages: predict-coco\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m   Building wheel for predict-coco (setup.py) ... \u001b[?25l/2020/07/15 18:33:39 [crit] 19#19: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:33:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 2020/07/15 18:33:44 [crit] 19#19: *9 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:33:44 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m-2020/07/15 18:33:49 [crit] 19#19: *11 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:33:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m\\2020/07/15 18:33:54 [crit] 19#19: *13 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:33:54 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 2020/07/15 18:33:59 [crit] 19#19: *15 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:33:59 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 2020/07/15 18:34:04 [crit] 19#19: *17 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:34:04 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m\\2020/07/15 18:34:09 [crit] 19#19: *19 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:34:09 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 2020/07/15 18:34:14 [crit] 19#19: *21 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:34:14 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 2020/07/15 18:34:19 [crit] 19#19: *23 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36malgo-1-f6lb3_1  |\u001b[0m 172.18.0.1 - - [15/Jul/2020:18:34:19 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"-\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bcbdb9748e8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{container_serving}-{tag}-local-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# define a unqie endpoint name; if ommited, Sagemaker will generate it based on used container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Key\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Value\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34mf\"{container_serving}:{tag}\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                          \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                          )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             )\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m         self.sagemaker_client.create_endpoint(\n\u001b[0;32m-> 2415\u001b[0;31m             \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2416\u001b[0m         )\n\u001b[1;32m   2417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, EndpointName, EndpointConfigName, Tags)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalEndpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mendpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEndpointConfigName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mserving_port\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local.serving_port\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m8080\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0m_wait_for_serving_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserving_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# the container is running and it passed the healthcheck status is now InService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LocalEndpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IN_SERVICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36m_wait_for_serving_container\u001b[0;34m(serving_port)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "                         instance_type = 'local_gpu',\n",
    "                         initial_instance_count=1,\n",
    "                         endpoint_name=f\"{container_serving}-{tag}-local-1\", # define a unqie endpoint name; if ommited, Sagemaker will generate it based on used container\n",
    "                         tags=[{\"Key\":\"image\", \"Value\":f\"{container_serving}:{tag}\"}], \n",
    "                         wait=False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/code/object-tracking-project/detectron2_train\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# upload model data to S3\n",
    "model_data = sagemaker_session.upload_data(path='d2.tar.gz',\n",
    "                                           bucket=bucket,\n",
    "                                           key_prefix =os.path.join(prefix, 'model'))\n",
    "\n",
    "# instantiate model\n",
    "torch_model = PyTorchModel(model_data=model_data,\n",
    "                           role=role,\n",
    "                           source_dir='/home/ec2-user/SageMaker/code/object-tracking-project/detectron2_train', # need to specify a directory here \n",
    "                           image='209419068016.dkr.ecr.us-east-1.amazonaws.com/detectron2-serve',\n",
    "                          entry_point='predict_coco.py',\n",
    "                          framework_version='1.5.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "# deploy endpoint, this part may take a bit\n",
    "endpoint_name = f'd2-endpoint-{datetime.datetime.fromtimestamp(time.time()).strftime(\"%c\").replace(\" \",\"-\").replace(\":\",\"-\")}'\n",
    "d2_end = torch_model.deploy(instance_type='ml.g4dn.2xlarge', initial_instance_count=1, \n",
    "                              endpoint_name=endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-97d050bcb773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                        \u001b[0mContentType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'application/x-npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                        Body=npy_serializer(img_arr))\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "img = Image.open('/home/ec2-user/SageMaker/game_clips/2020-07-21-12:52:35.967499/split_frames_00001.jpg')\n",
    "img = img.resize((512,512))\n",
    "img_arr = np.array(img, dtype=np.uint8) # np.uint8\n",
    "# endpoint_name = 'd2-endpoint-Wed-Aug-19-15-24-30-2020'\n",
    "# 'd2-endpoint-Thu-Jul-16-15-24-57-2020' # helmet model\n",
    "\n",
    "# response = d2_end.predict(json.dumps(payload), initial_args={'ContentType':'application/json'}) \n",
    "\n",
    "init_response = runtime_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                       ContentType='application/x-npy',\n",
    "                                       Body=npy_serializer(img_arr))\n",
    "response = eval(init_response['Body'].read().decode('utf-8'))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, stream, content_type)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCONTENT_TYPE_NPY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-05bb536684c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpy_serializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_deserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# nparr = np.asarray(resp, dtype=\"uint8\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, stream, content_type)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m         raise ValueError(\n\u001b[1;32m    630\u001b[0m             \"content_type must be one of the following: CSV, JSON, NPY. content_type: {}\".format(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "\n",
    "resp = npy_serializer(img_arr)\n",
    "img = numpy_deserializer(resp)\n",
    "# nparr = np.asarray(resp, dtype=\"uint8\")\n",
    "# img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "serial_arr = npy_serializer(img_arr)\n",
    "nparr = np.frombuffer(serial_arr, np.uint8)\n",
    "img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "input_object = np.asarray(img)\n",
    "input_object\n",
    "# sys.getsizeof(init_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, figsize=(24,14))\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(np.array(img_arr))\n",
    "\n",
    "# Create a Rectangle patch\n",
    "for i,labs in enumerate(response['pred_boxes']):\n",
    "    rect = patches.Rectangle((labs[0], labs[1]),labs[2]-labs[0],labs[3]-labs[1] ,linewidth=1,edgecolor='r',facecolor='none') # 50,100),40,30\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install ezsmdeploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ez = ezsmdeploy.Deploy(model = [modelpath], #loading pretrained MNIST model\n",
    "                  script = 'modelscript_pytorch.py',\n",
    "                  requirements = ['numpy','torch','joblib'], #or pass in the path to requirements.txt\n",
    "                  instance_type = 'local',\n",
    "                  wait = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
